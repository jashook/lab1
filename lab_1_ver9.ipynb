{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Attributes and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team: Frank Sclafani, Jan Shook, and Leticia Valadez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding\n",
    "\n",
    "## Rubric (10 pts)\n",
    "\n",
    "This initial phase focuses on understanding the project objective and requirement from a business perspective, and then converting this knowledge into a data mining problem definition, and a preliminary plan designed to achieve the objectives. A decision model, especially one built using the Decision Model and Notation standard can be used.\n",
    "\n",
    "> Describe the purpose of the data set you selected (i.e., why was this data collected in the ﬁrst place?). Describe how you would deﬁne and measure the outcomes from the dataset. That is, why is this data important and how do you know if you have mined useful knowledge from the dataset? How would you measure the effectiveness of a good prediction algorithm? Be speciﬁc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/html"
   },
   "source": [
    "## TV News Channel Commercial Detection\n",
    "\n",
    "Our team selected this dataset for two reasons: 1) It has a large number of instances (129,685, which is greater than the requirement of at least 30,000) and enough attributes (14, which is greater than the requirement of at least 10), and 2) It looks like an interesting dataset (detecting commercials). Initial questions of interest are how do you detect commercials from this data? Can a model be trained to detect and skip (or remove) commercials? If so, would this solution be robust enough for commercial products like TiVo?\n",
    "\n",
    "This dataset is from the UCI Machine Learning website (https://archive.ics.uci.edu/ml/datasets/TV+News+Channel+Commercial+Detection+Dataset). It consists of popular audio-visual features of video shots extracted from 150 hours of TV news broadcast of 3 Indian and 2 international news channels (30 Hours each). In the readme accompanying the data, the authors describe the potential benefits of this data as follows:\n",
    "\n",
    "> Automatic identification of commercial blocks in news videos finds a lot of applications in the domain of television broadcast analysis and monitoring. Commercials occupy almost 40-60% of total air time. Manual segmentation of commercials from thousands of TV news channels is time consuming, and economically infeasible hence prompts the need for machine learning based Method. Classifying TV News commercials is a semantic video classification problem. TV News commercials on particular news channel are combinations of video shots uniquely characterized by audio-visual presentation. Hence various audio visual features extracted from video shots are widely used for TV commercial classification. Indian News channels do not follow any particular news presentation format, have large variability and dynamic nature presenting a challenging machine learning problem. Features from 150 Hours of broadcast news videos from 5 different (3 Indian and 2 International News channels) news channels. Viz. CNNIBN, NDTV 24X7, TIMESNOW, BBC and CNN are presented in this dataset. Videos are recorded at resolution of 720 X 576 at 25 fps using a DVR and set top box. 3 Indian channels are recorded concurrently while 2 International are recorded together. Feature file preserves the order of occurrence of shots.\n",
    "\n",
    "Given this information, is the subset of Indian datasets really different from the international datasets? If so, can commercials still be identified from both Indian and international datasets the same way?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this Notebook\n",
    "\n",
    "This Jupyter (v4.3.0) notebook was developed on Windows 10 Pro (64 bit) using Anaconda v4.4.7 and Python v3.*.\n",
    "\n",
    "Packages associated with Anaconda were extracted as follows:\n",
    "\n",
    "> conda install -c anaconda pandas\n",
    "\n",
    "> conda install -c anaconda numpy \n",
    "\n",
    "In addition to the packages in Anaconda (and outside of the Anaconda ecosystem), this notebook uses Plotly (v2.2.3) for visualization. The zip file for Plotly can be found on GitHub at (https://github.com/plotly/plotly.py). You can install the Plotly packages as follows:\n",
    "\n",
    "> pip install plotly\n",
    "\n",
    "> pip install cufflinks\n",
    "\n",
    "The version of Pandas and its dependencies are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTALLED VERSIONS\n",
      "------------------\n",
      "commit: None\n",
      "python: 3.6.3.final.0\n",
      "python-bits: 64\n",
      "OS: Windows\n",
      "OS-release: 10\n",
      "machine: AMD64\n",
      "processor: Intel64 Family 6 Model 60 Stepping 3, GenuineIntel\n",
      "byteorder: little\n",
      "LC_ALL: None\n",
      "LANG: None\n",
      "LOCALE: None.None\n",
      "\n",
      "pandas: 0.22.0\n",
      "pytest: 3.2.1\n",
      "pip: 9.0.1\n",
      "setuptools: 36.5.0.post20170921\n",
      "Cython: 0.26.1\n",
      "numpy: 1.13.3\n",
      "scipy: 0.19.1\n",
      "pyarrow: None\n",
      "xarray: None\n",
      "IPython: 6.1.0\n",
      "sphinx: 1.6.3\n",
      "patsy: 0.4.1\n",
      "dateutil: 2.6.1\n",
      "pytz: 2017.2\n",
      "blosc: None\n",
      "bottleneck: 1.2.1\n",
      "tables: 3.4.2\n",
      "numexpr: 2.6.2\n",
      "feather: None\n",
      "matplotlib: 2.1.0\n",
      "openpyxl: 2.4.8\n",
      "xlrd: 1.1.0\n",
      "xlwt: 1.3.0\n",
      "xlsxwriter: 1.0.2\n",
      "lxml: 4.1.0\n",
      "bs4: 4.6.0\n",
      "html5lib: 0.999999999\n",
      "sqlalchemy: 1.1.13\n",
      "pymysql: None\n",
      "psycopg2: None\n",
      "jinja2: 2.9.6\n",
      "s3fs: None\n",
      "fastparquet: None\n",
      "pandas_gbq: None\n",
      "pandas_datareader: None\n",
      "Wall time: 3.87 s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "%time pd.show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "\n",
    "## Rubric (80 pts)\n",
    "\n",
    "The data understanding phase starts with an initial data collection and proceeds with activities in order to get familiar with the data, to identify data quality problems, to discover first insights into the data, or to detect interesting subsets to form hypotheses for hidden information.\n",
    "\n",
    "> [10 points] Describe the meaning and type of data (scale, values, etc.) for each attribute in the data ﬁle.\n",
    "\n",
    "> [15 points] Verify data quality: Explain any missing values, duplicate data, and outliers. Are those mistakes? How do you deal with these problems? Give justiﬁcations for your methods.\n",
    "\n",
    "> [10 points] Visualize appropriate statistics (e.g., range, mode, mean, median, variance, counts) for a subset of attributes. Describe anything meaningful you found from this or if you found something potentially interesting. Note: You can also use data from other sources for comparison. Explain why the statistics run are meaningful.\n",
    "\n",
    "> [15 points] Visualize the most interesting attributes (at least 5 attributes, your opinion on what is interesting). Important: Interpret the implications for each visualization. Explain for each attribute why the chosen visualization is appropriate.  \n",
    "Page ! of ! 17 39\n",
    " \n",
    "> [15 points] Visualize relationships between attributes: Look at the attributes via scatter plots, correlation, cross-tabulation, group-wise averages, etc. as appropriate. Explain any interesting relationships.\n",
    "\n",
    "> [10 points] Identify and explain interesting relationships between features and the class you are trying to predict (i.e., relationships with variables and the target classiﬁcation).\n",
    "\n",
    "> [5 points] Are there other features that could be added to the data or created from existing features?  Which ones?\n",
    "\n",
    "## Exceptional Work Rubric (10 pts)\n",
    "\n",
    "> [10 points total] You have free reign to provide additional analyses. One idea: implement dimensionality reduction, then visualize and interpret the results.\n",
    "\n",
    "\n",
    "## About this Dataset (Summary)\n",
    "\n",
    "This project is comprised of five datasets (bbc.txt, cnn.txt, cnnibn.txt, ndtv.txt, and timesnow.txt), all found at the UCI Machine Learning webset at https://archive.ics.uci.edu/ml/datasets/TV+News+Channel+Commercial+Detection+Dataset. Combined, these five datasets have 129,685 instances (rows) and 14 attributes. As shown in the example record below, most of these attributes have multiple data points (often hundreds) and almost all of these values are floating point.\n",
    "\n",
    "> 1  1:123 2:1.316440 3:1.516003 4:5.605905 5:5.346760 6:0.013233 7:0.010729 8:0.091743 9:0.050768 10:3808.067871 11:702.992493 12:7533.133301 13:1390.499268 14:971.098511 15:1894.978027 16:114.965019 17:45.018257 18:0.635224 19:0.095226 20:0.063398 21:0.061210 22:0.038319 23:0.018285 24:0.011113 25:0.007736 26:0.004864 27:0.004220 28:0.003273 29:0.002699 30:0.002553 31:0.002323 32:0.002108 33:0.002036 34:0.001792 35:0.001553 36:0.001250 37:0.001317 38:0.001084 39:0.000818 40:0.000624 41:0.000586 42:0.000529 43:0.000426 44:0.000359 45:0.000446 46:0.000268 47:0.000221 48:0.000154 49:0.000217 50:0.000193 51:0.000163 52:0.000165 53:0.000210 54:0.000114 55:0.000130 56:0.000055 57:0.000013 58:0.733037 59:0.133122 60:0.041263 61:0.019699 62:0.010962 63:0.006927 64:0.004525 65:0.003128 66:0.002314 67:0.001762 68:0.001361 69:0.001065 70:0.000914 71:0.000777 72:0.000667 73:0.000565 74:0.000520 75:0.000467 76:0.000469 77:0.000486 78:0.000417 79:0.000427 80:0.000349 81:0.000258 82:0.000262 83:0.000344 84:0.000168 85:0.000163 86:0.001058 90:0.020584 91:0.185038 92:0.148316 93:0.047098 94:0.169797 95:0.061318 96:0.002200 97:0.010440 98:0.004463 100:0.010558 101:0.002067 102:0.338970 103:0.470364 104:0.189997 105:0.018296 106:0.126517 107:0.047620 108:0.045863 109:0.184865 110:0.095976 111:0.015295 112:0.056323 113:0.024587 115:0.037647 116:0.006015 117:0.160327 118:0.251688 119:0.176144 123:0.006356 219:0.002119 276:0.002119 296:0.341102 448:0.099576 491:0.069915 572:0.141949 573:0.103814 601:0.002119 623:0.050847 726:0.038136 762:0.036017 816:0.036017 871:0.016949 924:0.008475 959:0.036017 1002:0.006356 1016:0.008475 1048:0.002119 4124:0.422333825949 4125:0.663917631952\n",
    "\n",
    "All five datasets are formated in the svmlight / libsvm format. This format is a text-based format, with one sample per line. It is a light format meaning it does not store zero valued features, every fetature that is \"missing\" has a value of zero. The first element of each line is used to store a target variable, and in this case it is the vaue of the atriburtes below. \n",
    "\n",
    "Hence, the file simply contains more records like the one shown above. While there are only 14 attributes in each dataset, most attributes can have more than one column of data. \n",
    "\n",
    "## Description of Attributes\n",
    "\n",
    "The following sections describe this dataset using the Readme.txt file, examination of the data, and definition of the terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We are using a Pandas dataframe to tabulate the data (and provide an simple introduction into Pandas)\n",
    "\n",
    "#Dimension Index  ... first column\n",
    "\n",
    "df_attributes = pd.DataFrame(\n",
    "  data=[\n",
    "    ('Dimension Index','0','integer',''),\n",
    "    ('Shot Length','1','integer',''),\n",
    "    ('Motion Distribution','2-3','float','Mean and Variance'),\n",
    "    ('Frame Difference Distribution','4-5','float','Mean and Variance'),\n",
    "    ('Short time energy','6-7','float','Mean and Variance'),\n",
    "    ('ZCR','8-9','float','Mean and Variance'),\n",
    "    ('Spectral Centroid','10-11','float','Mean and Variance'),\n",
    "    ('Spectral Roll off','12-13','float','Mean and Variance'),\n",
    "    ('Spectral Flux','14-15','float','Mean and Variance'),\n",
    "    ('Fundamental Frequency','16-17','float','Mean and Variance'),\n",
    "    ('Motion Distribution','18-58','float','40 bins'),\n",
    "    ('Frame Difference Distribution','59-91','float','32 bins'),\n",
    "    ('Text area distribution','92-122','float','15 bins Mean and 15 bins for variance'),\n",
    "    ('Bag of Audio Words','123-4123','float','4,000 bins'), \n",
    "    ('Edge change Ratio','4124-4125','float','Mean and Variance')\n",
    "  ],\n",
    "  columns=[\n",
    "    'Attribute Name','Columns','Datatype','Notes'\n",
    "  ],\n",
    "  index=[\n",
    "    'Attribute 00', 'Attribute 01', 'Attribute 02', 'Attribute 03', 'Attribute 04', 'Attribute 05', 'Attribute 06',\n",
    "    'Attribute 07', 'Attribute 08', 'Attribute 09', 'Attribute 10', 'Attribute 11', 'Attribute 12', 'Attribute 13',\n",
    "    'Attribute 14'\n",
    "  ]\n",
    ")\n",
    "\n",
    "# we will later omit the Bag of Audio Words attribute,\"123-4123\" to reduce the sparcity of the data.\n",
    "# tabulate is used to left justify these string value columns (versus the right-justified default)\n",
    "\n",
    "#from tabulate import tabulate\n",
    "\n",
    "#print(tabulate(df_attributes, showindex=True, headers=df_attributes.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute Descriptions\n",
    "\n",
    "### Shot Length \n",
    "Commercial video shots are usually short in length, fast visual transitions with peculiar placement of overlaid text bands. Video Shot Length is directly used as one of the feature.\n",
    "\n",
    "### Short time energy\n",
    "Short term energy can be used for voiced, unvoiced and silence classification of speech. The relation for finding the short term energy can be derived from the total energy relation defined in signal processing.The total energy of an energy signal is given by.\n",
    "\n",
    "### ZCR\n",
    "Zero Crossing Rate (aka ZCR) is the rate of sign-changes along a signal. This is used in both speech recognition and music information retrieval and it is a feature used to classify sounds. That is percicely its use case here in this dataset, it till be used as ont of the attributes to help differenciate commercials from the news program. \n",
    "\n",
    "### Spectral Centroid\n",
    "Spectral Centroid is a measure of the “center of gravity” using the fourier transform's frequency and magnitude information. It is commenly used in digital signal processing to help characterise a spectrum. \n",
    "\n",
    "### Spectral Roll off\n",
    "Spectral Rolloff Point is a measure measure of the amount of the right-skewedness of the power spectrum.\n",
    "\n",
    "### Spectral Flux\n",
    "Spectral flux is a measure of how quickly the power spectrum of a signal is changes. It is calculated by comparing the power spectrum for one frame against the power spectrum from the previous frame.\n",
    "\n",
    "### Fundamental Frequency\n",
    "The fundamental frequency is the lowest frequency of a wwaveform. In music, the fundamental is the musical pitch of a note that is perceived as the lowest partial present.\n",
    "\n",
    "### Motion Distribution\n",
    "Motion Distribution is obtained by first computing dense optical flow (Horn-Schunk formulation) followed by construction of a distribution of flow magnitudes over the entire shot with 40 uniformly divided bins in range of [0, 40].\n",
    "\n",
    "### Frame Difference Distribution\n",
    "The Frame Difference Distribution is the measure of the difference between the current frame and a reference frame, often called \"background image\", or \"background model\". This will assist in measuring the percieved speed at which the frames appear to differientate. Sudden changes in pixel intensities are grasped by Frame Difference Distribution. Such changes are not registered by optical flow. Thus, Frame Difference Distribution is also computed along with flow magnitude distributions. The researchers obtain the frame difference by averaging absolute frame difference in each of 3 color channels and the distribution is constructed with 32 bins in the range of [0, 255] .\n",
    "\n",
    "### Text area distribution\n",
    "The Test Difference Distribution is simular to the Test Difference Distribution in that is is the measure of the difference between the current text on screen and a reference amount of text. The text distribution feature is obtained by averaging the fraction of text area present in a grid block over all frames of the shot.\n",
    "\n",
    "### Bag of Audio Words\n",
    "This attribute is to be removed to reduce the sparsness of the data set.\n",
    "\n",
    "### Edge change Ratio\n",
    "Edge Change Ratio Captures the motion of edges between consecutive frames and is defined as ratio of displaced edge pixels to the total number of edge pixels in a frame. The researchers calculated the mean and variance of the ECR over the entire shot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute Name    Dimension Index\n",
      "Columns                         0\n",
      "Datatype                  integer\n",
      "Notes                            \n",
      "Name: Attribute 00, dtype: object\n",
      "Attribute Name    Shot Length\n",
      "Columns                     1\n",
      "Datatype              integer\n",
      "Notes                        \n",
      "Name: Attribute 01, dtype: object\n",
      "Attribute Name    Motion Distribution\n",
      "Columns                           2-3\n",
      "Datatype                        float\n",
      "Notes               Mean and Variance\n",
      "Name: Attribute 02, dtype: object\n",
      "Attribute Name    Frame Difference Distribution\n",
      "Columns                                     4-5\n",
      "Datatype                                  float\n",
      "Notes                         Mean and Variance\n",
      "Name: Attribute 03, dtype: object\n",
      "Attribute Name    Short time energy\n",
      "Columns                         6-7\n",
      "Datatype                      float\n",
      "Notes             Mean and Variance\n",
      "Name: Attribute 04, dtype: object\n",
      "Attribute Name                  ZCR\n",
      "Columns                         8-9\n",
      "Datatype                      float\n",
      "Notes             Mean and Variance\n",
      "Name: Attribute 05, dtype: object\n",
      "Attribute Name    Spectral Centroid\n",
      "Columns                       10-11\n",
      "Datatype                      float\n",
      "Notes             Mean and Variance\n",
      "Name: Attribute 06, dtype: object\n",
      "Attribute Name    Spectral Roll off\n",
      "Columns                       12-13\n",
      "Datatype                      float\n",
      "Notes             Mean and Variance\n",
      "Name: Attribute 07, dtype: object\n",
      "Attribute Name        Spectral Flux\n",
      "Columns                       14-15\n",
      "Datatype                      float\n",
      "Notes             Mean and Variance\n",
      "Name: Attribute 08, dtype: object\n",
      "Attribute Name    Fundamental Frequency\n",
      "Columns                           16-17\n",
      "Datatype                          float\n",
      "Notes                 Mean and Variance\n",
      "Name: Attribute 09, dtype: object\n",
      "Attribute Name    Motion Distribution\n",
      "Columns                         18-58\n",
      "Datatype                        float\n",
      "Notes                         40 bins\n",
      "Name: Attribute 10, dtype: object\n",
      "Attribute Name    Frame Difference Distribution\n",
      "Columns                                   59-91\n",
      "Datatype                                  float\n",
      "Notes                                   32 bins\n",
      "Name: Attribute 11, dtype: object\n",
      "Attribute Name                   Text area distribution\n",
      "Columns                                          92-122\n",
      "Datatype                                          float\n",
      "Notes             15 bins Mean and 15 bins for variance\n",
      "Name: Attribute 12, dtype: object\n",
      "Attribute Name    Bag of Audio Words\n",
      "Columns                     123-4123\n",
      "Datatype                       float\n",
      "Notes                     4,000 bins\n",
      "Name: Attribute 13, dtype: object\n",
      "Attribute Name    Edge change Ratio\n",
      "Columns                   4124-4125\n",
      "Datatype                      float\n",
      "Notes             Mean and Variance\n",
      "Name: Attribute 14, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#print(df_temp1[0].column)\n",
    "\n",
    "#pd.set_option('display.max_row', 1000)\n",
    "#pd.set_option('display.max_columns', 150)\n",
    "\n",
    "df_attributes.rename(columns={0: 'Dimension Index'}, inplace=True)\n",
    "df_attributes.rename(columns={1: 'Shot'}, inplace=True)\n",
    "df_attributes.rename(columns={2: 'Motion Distribution-Mean'}, inplace=True)\n",
    "df_attributes.rename(columns={3: 'Motion Distribution-Variance'}, inplace=True)\n",
    "df_attributes.rename(columns={4: 'Frame Difference Distribution-Mean'}, inplace=True)\n",
    "df_attributes.rename(columns={5: 'Frame Difference Distribution-Variance'}, inplace=True)\n",
    "df_attributes.rename(columns={6: 'Short time energy-Mean'}, inplace=True)\n",
    "df_attributes.rename(columns={7: 'Short time energy-Variance'}, inplace=True)\n",
    "df_attributes.rename(columns={8: 'ZCR-Mean'}, inplace=True)\n",
    "df_attributes.rename(columns={9: 'ZCR-Variance'}, inplace=True)\n",
    "df_attributes.rename(columns={10: 'Spectral Centroid-Mean'}, inplace=True)\n",
    "df_attributes.rename(columns={11: 'Spectral Centroid-Variance'}, inplace=True)\n",
    "df_attributes.rename(columns={12: 'Spectral Roll off-Mean'}, inplace=True)\n",
    "df_attributes.rename(columns={13: 'Spectral Roll off-Variance'}, inplace=True)\n",
    "df_attributes.rename(columns={14: 'Spectral Flux-Mean'}, inplace=True)\n",
    "df_attributes.rename(columns={15: 'Spectral Flux-Variance'}, inplace=True)\n",
    "df_attributes.rename(columns={16: 'Fundamental Frequency-Mean'}, inplace=True)\n",
    "df_attributes.rename(columns={17: 'Fundamental Frequency-Variance'}, inplace=True)\n",
    "df_attributes.rename(columns={18: 'Motion Distribution-Bin 1'}, inplace=True)\n",
    "df_attributes.rename(columns={19: 'Motion Distribution-Bin 2'}, inplace=True)\n",
    "df_attributes.rename(columns={20: 'Motion Distribution-Bin 3'}, inplace=True)\n",
    "df_attributes.rename(columns={21: 'Motion Distribution-Bin 4'}, inplace=True)\n",
    "df_attributes.rename(columns={22: 'Motion Distribution-Bin 5'}, inplace=True)\n",
    "df_attributes.rename(columns={23: 'Motion Distribution-Bin 6'}, inplace=True)\n",
    "df_attributes.rename(columns={24: 'Motion Distribution-Bin 7'}, inplace=True)\n",
    "df_attributes.rename(columns={25: 'Motion Distribution-Bin 8'}, inplace=True)\n",
    "df_attributes.rename(columns={26: 'Motion Distribution-Bin 9'}, inplace=True)\n",
    "df_attributes.rename(columns={27: 'Motion Distribution-Bin 10'}, inplace=True)\n",
    "df_attributes.rename(columns={28: 'Motion Distribution-Bin 11'}, inplace=True)\n",
    "df_attributes.rename(columns={29: 'Motion Distribution-Bin 12'}, inplace=True)\n",
    "df_attributes.rename(columns={30: 'Motion Distribution-Bin 13'}, inplace=True)\n",
    "df_attributes.rename(columns={31: 'Motion Distribution-Bin 14'}, inplace=True)\n",
    "df_attributes.rename(columns={32: 'Motion Distribution-Bin 15'}, inplace=True)\n",
    "df_attributes.rename(columns={33: 'Motion Distribution-Bin 16'}, inplace=True)\n",
    "df_attributes.rename(columns={34: 'Motion Distribution-Bin 17'}, inplace=True)\n",
    "df_attributes.rename(columns={35: 'Motion Distribution-Bin 18'}, inplace=True)\n",
    "df_attributes.rename(columns={36: 'Motion Distribution-Bin 19'}, inplace=True)\n",
    "df_attributes.rename(columns={37: 'Motion Distribution-Bin 20'}, inplace=True)\n",
    "df_attributes.rename(columns={38: 'Motion Distribution-Bin 21'}, inplace=True)\n",
    "df_attributes.rename(columns={39: 'Motion Distribution-Bin 22'}, inplace=True)\n",
    "df_attributes.rename(columns={40: 'Motion Distribution-Bin 23'}, inplace=True)\n",
    "df_attributes.rename(columns={41: 'Motion Distribution-Bin 24'}, inplace=True)\n",
    "df_attributes.rename(columns={42: 'Motion Distribution-Bin 25'}, inplace=True)\n",
    "df_attributes.rename(columns={43: 'Motion Distribution-Bin 26'}, inplace=True)\n",
    "df_attributes.rename(columns={44: 'Motion Distribution-Bin 27'}, inplace=True)\n",
    "df_attributes.rename(columns={45: 'Motion Distribution-Bin 28'}, inplace=True)\n",
    "df_attributes.rename(columns={46: 'Motion Distribution-Bin 29'}, inplace=True)\n",
    "df_attributes.rename(columns={47: 'Motion Distribution-Bin 30'}, inplace=True)\n",
    "df_attributes.rename(columns={48: 'Motion Distribution-Bin 31'}, inplace=True)\n",
    "df_attributes.rename(columns={49: 'Motion Distribution-Bin 32'}, inplace=True)\n",
    "df_attributes.rename(columns={50: 'Motion Distribution-Bin 33'}, inplace=True)\n",
    "df_attributes.rename(columns={51: 'Motion Distribution-Bin 34'}, inplace=True)\n",
    "df_attributes.rename(columns={52: 'Motion Distribution-Bin 35'}, inplace=True)\n",
    "df_attributes.rename(columns={53: 'Motion Distribution-Bin 36'}, inplace=True)\n",
    "df_attributes.rename(columns={54: 'Motion Distribution-Bin 37'}, inplace=True)\n",
    "df_attributes.rename(columns={55: 'Motion Distribution-Bin 38'}, inplace=True)\n",
    "df_attributes.rename(columns={56: 'Motion Distribution-Bin 39'}, inplace=True)\n",
    "df_attributes.rename(columns={57: 'Motion Distribution-Bin 40'}, inplace=True)\n",
    "\n",
    "# NOTE: Attribute 58 should be Bin 40 ... don't know what's wrong (other than readme.txt)\n",
    "\n",
    "df_attributes.rename(columns={58: 'Attribute 58 should be Bin 40'}, inplace=True)\n",
    "\n",
    "df_attributes.rename(columns={59: 'Frame Difference Distribution-Bin 1'}, inplace=True)\n",
    "df_attributes.rename(columns={60: 'Frame Difference Distribution-Bin 2'}, inplace=True)\n",
    "df_attributes.rename(columns={61: 'Frame Difference Distribution-Bin 3'}, inplace=True)\n",
    "df_attributes.rename(columns={62: 'Frame Difference Distribution-Bin 4'}, inplace=True)\n",
    "df_attributes.rename(columns={63: 'Frame Difference Distribution-Bin 5'}, inplace=True)\n",
    "df_attributes.rename(columns={64: 'Frame Difference Distribution-Bin 6'}, inplace=True)\n",
    "df_attributes.rename(columns={65: 'Frame Difference Distribution-Bin 7'}, inplace=True)\n",
    "df_attributes.rename(columns={66: 'Frame Difference Distribution-Bin 8'}, inplace=True)\n",
    "df_attributes.rename(columns={67: 'Frame Difference Distribution-Bin 9'}, inplace=True)\n",
    "df_attributes.rename(columns={68: 'Frame Difference Distribution-Bin 10'}, inplace=True)\n",
    "df_attributes.rename(columns={69: 'Frame Difference Distribution-Bin 11'}, inplace=True)\n",
    "df_attributes.rename(columns={70: 'Frame Difference Distribution-Bin 12'}, inplace=True)\n",
    "df_attributes.rename(columns={71: 'Frame Difference Distribution-Bin 13'}, inplace=True)\n",
    "df_attributes.rename(columns={72: 'Frame Difference Distribution-Bin 14'}, inplace=True)\n",
    "df_attributes.rename(columns={73: 'Frame Difference Distribution-Bin 15'}, inplace=True)\n",
    "df_attributes.rename(columns={74: 'Frame Difference Distribution-Bin 16'}, inplace=True)\n",
    "df_attributes.rename(columns={75: 'Frame Difference Distribution-Bin 17'}, inplace=True)\n",
    "df_attributes.rename(columns={76: 'Frame Difference Distribution-Bin 18'}, inplace=True)\n",
    "df_attributes.rename(columns={77: 'Frame Difference Distribution-Bin 19'}, inplace=True)\n",
    "df_attributes.rename(columns={78: 'Frame Difference Distribution-Bin 20'}, inplace=True)\n",
    "df_attributes.rename(columns={79: 'Frame Difference Distribution-Bin 21'}, inplace=True)\n",
    "df_attributes.rename(columns={80: 'Frame Difference Distribution-Bin 22'}, inplace=True)\n",
    "df_attributes.rename(columns={81: 'Frame Difference Distribution-Bin 23'}, inplace=True)\n",
    "df_attributes.rename(columns={82: 'Frame Difference Distribution-Bin 24'}, inplace=True)\n",
    "df_attributes.rename(columns={83: 'Frame Difference Distribution-Bin 25'}, inplace=True)\n",
    "df_attributes.rename(columns={84: 'Frame Difference Distribution-Bin 26'}, inplace=True)\n",
    "df_attributes.rename(columns={85: 'Frame Difference Distribution-Bin 27'}, inplace=True)\n",
    "df_attributes.rename(columns={86: 'Frame Difference Distribution-Bin 28'}, inplace=True)\n",
    "df_attributes.rename(columns={87: 'Frame Difference Distribution-Bin 29'}, inplace=True)\n",
    "df_attributes.rename(columns={88: 'Frame Difference Distribution-Bin 30'}, inplace=True)\n",
    "df_attributes.rename(columns={89: 'Frame Difference Distribution-Bin 31'}, inplace=True)\n",
    "df_attributes.rename(columns={90: 'Frame Difference Distribution-Bin 32'}, inplace=True)\n",
    "\n",
    "# NOTE: Attribute 91 should be Bin 32 ... don't know what's wrong (other than readme.txt)\n",
    "\n",
    "df_attributes.rename(columns={91: 'Attribute 91 should be Bin 32'}, inplace=True)\n",
    "\n",
    "df_attributes.rename(columns={92: 'Text area distribution-Bin 1-Mean'}, inplace=True)\n",
    "df_attributes.rename(columns={93: 'Text area distribution-Bin 2-Mean'}, inplace=True)\n",
    "df_attributes.rename(columns={94: 'Text area distribution-Bin 3-Mean'}, inplace=True)\n",
    "df_attributes.rename(columns={95: 'Text area distribution-Bin 4-Mean'}, inplace=True)\n",
    "df_attributes.rename(columns={96: 'Text area distribution-Bin 5-Mean'}, inplace=True)\n",
    "df_attributes.rename(columns={97: 'Text area distribution-Bin 6-Mean'}, inplace=True)\n",
    "df_attributes.rename(columns={98: 'Text area distribution-Bin 7-Mean'}, inplace=True)\n",
    "df_attributes.rename(columns={99: 'Text area distribution-Bin 8-Mean'}, inplace=True)\n",
    "df_attributes.rename(columns={100: 'Text area distribution-Bin 9-Mean'}, inplace=True)\n",
    "df_attributes.rename(columns={101: 'Text area distribution-Bin 10-Mean'}, inplace=True)\n",
    "df_attributes.rename(columns={102: 'Text area distribution-Bin 11-Mean'}, inplace=True)\n",
    "df_attributes.rename(columns={103: 'Text area distribution-Bin 12-Mean'}, inplace=True)\n",
    "df_attributes.rename(columns={104: 'Text area distribution-Bin 13-Mean'}, inplace=True)\n",
    "df_attributes.rename(columns={105: 'Text area distribution-Bin 14-Mean'}, inplace=True)\n",
    "df_attributes.rename(columns={106: 'Text area distribution-Bin 15-Mean'}, inplace=True)\n",
    "df_attributes.rename(columns={107: 'Text area distribution-Bin 1-Variance'}, inplace=True)\n",
    "df_attributes.rename(columns={108: 'Text area distribution-Bin 2-Variance'}, inplace=True)\n",
    "df_attributes.rename(columns={109: 'Text area distribution-Bin 3-Variance'}, inplace=True)\n",
    "df_attributes.rename(columns={110: 'Text area distribution-Bin 4-Variance'}, inplace=True)\n",
    "df_attributes.rename(columns={111: 'Text area distribution-Bin 5-Variance'}, inplace=True)\n",
    "df_attributes.rename(columns={112: 'Text area distribution-Bin 6-Variance'}, inplace=True)\n",
    "df_attributes.rename(columns={113: 'Text area distribution-Bin 7-Variance'}, inplace=True)\n",
    "df_attributes.rename(columns={114: 'Text area distribution-Bin 8-Variance'}, inplace=True)\n",
    "df_attributes.rename(columns={115: 'Text area distribution-Bin 9-Variance'}, inplace=True)\n",
    "df_attributes.rename(columns={116: 'Text area distribution-Bin 10-Variance'}, inplace=True)\n",
    "df_attributes.rename(columns={117: 'Text area distribution-Bin 11-Variance'}, inplace=True)\n",
    "df_attributes.rename(columns={118: 'Text area distribution-Bin 12-Variance'}, inplace=True)\n",
    "df_attributes.rename(columns={119: 'Text area distribution-Bin 13-Variance'}, inplace=True)\n",
    "df_attributes.rename(columns={120: 'Text area distribution-Bin 14-Variance'}, inplace=True)\n",
    "df_attributes.rename(columns={121: 'Text area distribution-Bin 15-Variance'}, inplace=True)\n",
    "\n",
    "# NOTE: Attribute 122 should be Bin 15-Variance ... don't know what's wrong (other than readme.txt)\n",
    "\n",
    "df_attributes.rename(columns={122: 'Attribute 122 should be Bin 15-Variance'}, inplace=True)\n",
    "\n",
    "df_attributes.rename(columns={121: 'Text area distribution-Bin 15-Variance'}, inplace=True)\n",
    "\n",
    "for index, row in df_attributes.iterrows():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "This section covers the activities needed to construct the dataset that will be fed into the models. The files for this project  (bbc.txt, cnn.txt, cnnibn.txt, ndtv.txt, and timesnow.txt) can be found at  https://archive.ics.uci.edu/ml/datasets/TV+News+Channel+Commercial+Detection+Dataset as a single ZIP file. To eliminate  manual work and streamline file processing, these five files were extracted and put on a team member's website (http://www.shookfamily.org) as follows:\n",
    "\n",
    "http://www.shookfamily.org/data/BBC.txt (17,720 lines)\n",
    "\n",
    "http://www.shookfamily.org/data/CNN.txt (22,545 lines)\n",
    "\n",
    "http://www.shookfamily.org/data/CNNIBN.txt (33,117 lines)\n",
    "\n",
    "http://www.shookfamily.org/data/NDTV.txt (17,051 lines)\n",
    "\n",
    "http://www.shookfamily.org/data/TIMESNOW.txt (39,252 lines)\n",
    "\n",
    "As shown in the cells below, it takes several steps to download the files and process them into the final dataset.\n",
    "\n",
    "The overall goal is to download the files from the internet and load them into an in-memory object. Because these files are stored in the SVM Light format, they are first loaded into a scipy.sparse matrix array object. These sparse matrix arrays are then inspected to eliminate as many columns as possible, and, consequently, reduce the sparseness of the matrix. Once that is accomplished, the scipy.sparse matrix arrays are converted to Pandas DataFrames for faster data processing and input into the accompanying data models.\n",
    "\n",
    "\n",
    "## Step 1: Download Files\n",
    "\n",
    "The first step in this proces is to download the five files from the internet. The data is in a pickled (marshalled / serialized) format used to persist an SVM Light dataset. The SVM Light format is basically an Index : Value pair where the index represents an element in a sparse matrix array and the value associated with that element. For example, a partial record like the following:\n",
    "\n",
    "> 1 1:123 2:1.316440 3:1.516003 ...\n",
    "\n",
    "represents the Y-axis lable followed by the X-Axis values where the first, second, and third elements are a sparse matrix array with the values 123, 1.316440, and 1.516003 (or array[0] == 123, array[1] == 1.316440, and array[2] == 1.516003. The code below downloads each SVM Light file from the internet as a scipy.sparse matrix object. \n",
    "\n",
    "Note: It takes about 30 to 60 seconds to perform all five downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading datasets from the internet ...\n",
      "\n",
      "Downloading (as scipy.sparse matrix) ... http://www.shookfamily.org/data/BBC.txt\n",
      "Wall time: 3.71 s\n",
      "Downloading (as scipy.sparse matrix) ... http://www.shookfamily.org/data/CNN.txt\n",
      "Wall time: 5.88 s\n",
      "Downloading (as scipy.sparse matrix) ... http://www.shookfamily.org/data/CNNIBN.txt\n",
      "Wall time: 8.6 s\n",
      "Downloading (as scipy.sparse matrix) ... http://www.shookfamily.org/data/NDTV.txt\n",
      "Wall time: 4.45 s\n",
      "Downloading (as scipy.sparse matrix) ... http://www.shookfamily.org/data/TIMESNOW.txt\n",
      "Wall time: 10.1 s\n",
      "\n",
      "All files have been downloaded\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import tempfile\n",
    "\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "url_bbc      = 'http://www.shookfamily.org/data/BBC.txt'\n",
    "url_cnn      = 'http://www.shookfamily.org/data/CNN.txt'\n",
    "url_cnnibn   = 'http://www.shookfamily.org/data/CNNIBN.txt'\n",
    "url_ndtv     = 'http://www.shookfamily.org/data/NDTV.txt'\n",
    "url_timesnow = 'http://www.shookfamily.org/data/TIMESNOW.txt'\n",
    "\n",
    "################################################################################\n",
    "# Download file to a temporary file. Load that file into a scipy.sparse matrix\n",
    "# array, and then return that object to the caller.\n",
    "################################################################################\n",
    "\n",
    "def get_pickled_file(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.read()      # a `bytes` object\n",
    "    text = data.decode('utf-8') # a `str`; this step can't be used if data is binary\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(delete=False, mode='w') as file_handle:\n",
    "        assert text is not None\n",
    "        file_handle.write(text)\n",
    "        filename = file_handle.name\n",
    "\n",
    "        data = load_svmlight_file(filename)\n",
    "\n",
    "        return data[0],data[1]   # data[0] == X axis and data[1] == Y axis\n",
    "\n",
    "################################################################################\n",
    "# Dowload files as scipy.sparse matrix arrays\n",
    "################################################################################\n",
    "\n",
    "print('Downloading datasets from the internet ...\\n')\n",
    "print('Downloading (as scipy.sparse matrix) ...', url_bbc)\n",
    "\n",
    "%time sm_bbc = get_pickled_file(url_bbc)\n",
    "\n",
    "print('Downloading (as scipy.sparse matrix) ...', url_cnn)\n",
    "\n",
    "%time sm_cnn = get_pickled_file(url_cnn)\n",
    "\n",
    "print('Downloading (as scipy.sparse matrix) ...', url_cnnibn)\n",
    "\n",
    "%time sm_cnnibn = get_pickled_file(url_cnnibn)\n",
    "\n",
    "print('Downloading (as scipy.sparse matrix) ...', url_ndtv)\n",
    "\n",
    "%time sm_ndtv = get_pickled_file(url_ndtv)\n",
    "\n",
    "print('Downloading (as scipy.sparse matrix) ...', url_timesnow)\n",
    "\n",
    "%time sm_timesnow = get_pickled_file(url_timesnow)\n",
    "\n",
    "print('\\nAll files have been downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Convert to X-axis to Pandas Sparse Dataframes\n",
    "\n",
    "This step converts the scipy.sparse matrix arrays (X axis) into Pandas Sparse Dataframes (to get them into the Panda ecosystem).\n",
    "\n",
    "Note: It takes about 5 minutes to perform these conversions (~1 minute per conversion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting scipy.sparse matrix arrays to Pandas Sparse Dataframes ...\n",
      "\n",
      "Converting sm_bbc[0] to sdf_bbcX ...\n",
      "Wall time: 639 ms\n",
      "Converting sm_cnn[0] to sdf_cnnX ...\n",
      "Wall time: 724 ms\n",
      "Converting sm_ibn[0] to sdf_cnnibnX ...\n",
      "Wall time: 886 ms\n",
      "Converting sm_ndtv[0] to sdf_ndtvX ...\n",
      "Wall time: 679 ms\n",
      "Converting sm_timesnow[0] to sdf_timesnowX ...\n",
      "Wall time: 1.03 s\n",
      "\n",
      "All scipy.sparse matrix arrays have been converted to Pandas Sparse Dataframes\n",
      "\n",
      "<class 'pandas.core.sparse.frame.SparseDataFrame'>\n",
      "RangeIndex: 17720 entries, 0 to 17719\n",
      "Columns: 4125 entries, 0 to 4124\n",
      "dtypes: float64(4125)\n",
      "memory usage: 13.8 MB\n",
      "None\n",
      "<class 'pandas.core.sparse.frame.SparseDataFrame'>\n",
      "RangeIndex: 22545 entries, 0 to 22544\n",
      "Columns: 4125 entries, 0 to 4124\n",
      "dtypes: float64(4125)\n",
      "memory usage: 22.1 MB\n",
      "None\n",
      "<class 'pandas.core.sparse.frame.SparseDataFrame'>\n",
      "RangeIndex: 33117 entries, 0 to 33116\n",
      "Columns: 4125 entries, 0 to 4124\n",
      "dtypes: float64(4125)\n",
      "memory usage: 32.0 MB\n",
      "None\n",
      "<class 'pandas.core.sparse.frame.SparseDataFrame'>\n",
      "RangeIndex: 17051 entries, 0 to 17050\n",
      "Columns: 4125 entries, 0 to 4124\n",
      "dtypes: float64(4125)\n",
      "memory usage: 16.4 MB\n",
      "None\n",
      "<class 'pandas.core.sparse.frame.SparseDataFrame'>\n",
      "RangeIndex: 39252 entries, 0 to 39251\n",
      "Columns: 4125 entries, 0 to 4124\n",
      "dtypes: float64(4125)\n",
      "memory usage: 38.1 MB\n",
      "None\n",
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# This code creates the Pandas Sparse Dataframes from the X axis\n",
    "\n",
    "print('Converting scipy.sparse matrix arrays to Pandas Sparse Dataframes ...\\n')\n",
    "print('Converting sm_bbc[0] to sdf_bbcX ...')\n",
    "\n",
    "%time sdf_bbcX = pd.SparseDataFrame(sm_bbc[0])\n",
    "\n",
    "print('Converting sm_cnn[0] to sdf_cnnX ...')\n",
    "\n",
    "%time sdf_cnnX = pd.SparseDataFrame(sm_cnn[0])\n",
    "\n",
    "print('Converting sm_ibn[0] to sdf_cnnibnX ...')\n",
    "\n",
    "%time sdf_cnnibnX = pd.SparseDataFrame(sm_cnnibn[0])\n",
    "\n",
    "print('Converting sm_ndtv[0] to sdf_ndtvX ...')\n",
    "\n",
    "%time sdf_ndtvX = pd.SparseDataFrame(sm_ndtv[0])\n",
    "\n",
    "print('Converting sm_timesnow[0] to sdf_timesnowX ...')\n",
    "\n",
    "%time sdf_timesnowX = pd.SparseDataFrame(sm_timesnow[0])\n",
    "\n",
    "print('\\nAll scipy.sparse matrix arrays have been converted to Pandas Sparse Dataframes\\n')\n",
    "print(sdf_bbcX.info())\n",
    "print(sdf_cnnX.info())\n",
    "print(sdf_cnnibnX.info())\n",
    "print(sdf_ndtvX.info())\n",
    "print(sdf_timesnowX.info())\n",
    "\n",
    "print('\\nDONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Convert Y-axis to Pandas Sparse Dataframes\n",
    "\n",
    "This step converts the scipy.sparse matrix array (Y axis) into a Pandas Sparse Dataframe (to get it into the Panda ecosystem).\n",
    "\n",
    "Note: It takes just a few seconds to perform these conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting scipy.sparse matrix array to Pandas Sparse Dataframe ...\n",
      "\n",
      "Converting sm_bbc[1] to sdf_bbcY ...\n",
      "Wall time: 1e+03 µs\n",
      "<class 'pandas.core.sparse.frame.SparseDataFrame'>\n",
      "RangeIndex: 17720 entries, 0 to 17719\n",
      "Data columns (total 1 columns):\n",
      "0    17720 non-null float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 138.5 KB\n",
      "None\n",
      "     0\n",
      "0  1.0\n",
      "1  1.0\n",
      "2  1.0\n",
      "3  1.0\n",
      "4  1.0\n",
      "\n",
      "Converting sm_cnn[1] to sdf_cnnY ...\n",
      "Wall time: 0 ns\n",
      "<class 'pandas.core.sparse.frame.SparseDataFrame'>\n",
      "RangeIndex: 22545 entries, 0 to 22544\n",
      "Data columns (total 1 columns):\n",
      "0    22545 non-null float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 176.2 KB\n",
      "None\n",
      "     0\n",
      "0  1.0\n",
      "1  1.0\n",
      "2  1.0\n",
      "3  1.0\n",
      "4  1.0\n",
      "\n",
      "Converting sm_cnnibn[1] to sdf_cnnibmY ...\n",
      "Wall time: 2 ms\n",
      "<class 'pandas.core.sparse.frame.SparseDataFrame'>\n",
      "RangeIndex: 33117 entries, 0 to 33116\n",
      "Data columns (total 1 columns):\n",
      "0    33117 non-null float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 258.8 KB\n",
      "None\n",
      "     0\n",
      "0  1.0\n",
      "1  1.0\n",
      "2  1.0\n",
      "3  1.0\n",
      "4  1.0\n",
      "\n",
      "Converting sm_ndtv[1] to sdf_ndtvY ...\n",
      "Wall time: 1 ms\n",
      "<class 'pandas.core.sparse.frame.SparseDataFrame'>\n",
      "RangeIndex: 17051 entries, 0 to 17050\n",
      "Data columns (total 1 columns):\n",
      "0    17051 non-null float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 133.3 KB\n",
      "None\n",
      "     0\n",
      "0  1.0\n",
      "1  1.0\n",
      "2  1.0\n",
      "3  1.0\n",
      "4  1.0\n",
      "\n",
      "Converting sm_timesnow[1] to sdf_timesnowY ...\n",
      "Wall time: 1e+03 µs\n",
      "<class 'pandas.core.sparse.frame.SparseDataFrame'>\n",
      "RangeIndex: 39252 entries, 0 to 39251\n",
      "Data columns (total 1 columns):\n",
      "0    39252 non-null float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 306.7 KB\n",
      "None\n",
      "     0\n",
      "0  1.0\n",
      "1  1.0\n",
      "2  1.0\n",
      "3  1.0\n",
      "4  1.0\n",
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print('Converting scipy.sparse matrix array to Pandas Sparse Dataframe ...')\n",
    "\n",
    "print('\\nConverting sm_bbc[1] to sdf_bbcY ...')\n",
    "%time sdf_bbcY = pd.SparseDataFrame(sm_bbc[1])\n",
    "print(sdf_bbcY.info())\n",
    "print(sdf_bbcY.head())\n",
    "\n",
    "print('\\nConverting sm_cnn[1] to sdf_cnnY ...')\n",
    "%time sdf_cnnY = pd.SparseDataFrame(sm_cnn[1])\n",
    "print(sdf_cnnY.info())\n",
    "print(sdf_cnnY.head())\n",
    "\n",
    "print('\\nConverting sm_cnnibn[1] to sdf_cnnibmY ...')\n",
    "%time sdf_cnnibnY = pd.SparseDataFrame(sm_cnnibn[1])\n",
    "print(sdf_cnnibnY.info())\n",
    "print(sdf_cnnibnY.head())\n",
    "\n",
    "print('\\nConverting sm_ndtv[1] to sdf_ndtvY ...')\n",
    "%time sdf_ndtvY = pd.SparseDataFrame(sm_ndtv[1])\n",
    "print(sdf_ndtvY.info())\n",
    "print(sdf_ndtvY.head())\n",
    "\n",
    "print('\\nConverting sm_timesnow[1] to sdf_timesnowY ...')\n",
    "%time sdf_timesnowY = pd.SparseDataFrame(sm_timesnow[1])\n",
    "print(sdf_timesnowY.info())\n",
    "print(sdf_timesnowY.head())\n",
    "\n",
    "print('\\nDONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to a Fixed DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17720 entries, 0 to 17719\n",
      "Columns: 4125 entries, 0 to 4124\n",
      "dtypes: float64(4125)\n",
      "memory usage: 13.8 MB\n",
      "None\n",
      "    0         1         2          3         4         5         6     \\\n",
      "0  123.0  1.316440  1.516003   5.605905  5.346760  0.013233  0.010729   \n",
      "1  124.0  0.966079  0.546420   4.046537  3.190973  0.008338  0.011490   \n",
      "2  109.0  2.035407  0.571643   9.551406  5.803685  0.015189  0.014294   \n",
      "3   86.0  3.206008  0.786326  10.092709  2.693058  0.013962  0.011039   \n",
      "4   76.0  3.135861  0.896346  10.348035  2.651010  0.020914  0.012061   \n",
      "\n",
      "       7         8            9       ...     4115  4116  4117  4118  4119  \\\n",
      "0  0.091743  0.050768  3808.067871    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "1  0.075504  0.065841  3466.266113    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "2  0.094209  0.044991  3798.196533    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "3  0.092042  0.043756  3761.712402    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "4  0.108018  0.052617  3784.488037    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "\n",
      "   4120  4121  4122      4123      4124  \n",
      "0   NaN   NaN   NaN  0.422334  0.663918  \n",
      "1   NaN   NaN   NaN  0.332664  0.766184  \n",
      "2   NaN   NaN   NaN  0.346674  0.225022  \n",
      "3   NaN   NaN   NaN  0.993323  0.840083  \n",
      "4   NaN   NaN   NaN  0.341520  0.710470  \n",
      "\n",
      "[5 rows x 4125 columns]\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22545 entries, 0 to 22544\n",
      "Columns: 4125 entries, 0 to 4124\n",
      "dtypes: float64(4125)\n",
      "memory usage: 22.1 MB\n",
      "None\n",
      "   0         1         2          3          4         5         6     \\\n",
      "0  29.0  3.821209  1.567568  13.547628   7.242389  0.019883  0.012195   \n",
      "1  25.0  3.052969  1.641484  22.334589  15.734018  0.023027  0.010731   \n",
      "2  82.0  1.601274  1.508805   5.860583   3.301121  0.025948  0.006956   \n",
      "3  25.0  4.819368  2.879584  41.382828  24.448074  0.014387  0.007596   \n",
      "4  29.0  2.768753  1.797319  13.338054   9.980667  0.011506  0.007269   \n",
      "\n",
      "       7         8            9       ...     4115  4116  4117  4118  4119  \\\n",
      "0  0.067241  0.049107  3406.866211    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "1  0.077000  0.045884  3324.158203    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "2  0.082317  0.044845  3771.984131    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "3  0.069875  0.046916  3301.686035    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "4  0.100647  0.067401  3266.021484    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "\n",
      "   4120  4121  4122      4123      4124  \n",
      "0   NaN   NaN   NaN  0.813823  0.397715  \n",
      "1   NaN   NaN   NaN  0.171117  0.989377  \n",
      "2   NaN   NaN   NaN  0.352850  0.848254  \n",
      "3   NaN   NaN   NaN  0.633264  0.553004  \n",
      "4   NaN   NaN   NaN  0.529880  0.585360  \n",
      "\n",
      "[5 rows x 4125 columns]\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33117 entries, 0 to 33116\n",
      "Columns: 4125 entries, 0 to 4124\n",
      "dtypes: float64(4125)\n",
      "memory usage: 32.0 MB\n",
      "None\n",
      "   0         1         2          3          4         5         6     \\\n",
      "0  29.0  3.821209  1.567568  13.547628   7.242389  0.019883  0.012195   \n",
      "1  25.0  3.052969  1.641484  22.334589  15.734018  0.023027  0.010731   \n",
      "2  82.0  1.601274  1.508805   5.860583   3.301121  0.025948  0.006956   \n",
      "3  25.0  4.819368  2.879584  41.382828  24.448074  0.014387  0.007596   \n",
      "4  29.0  2.768753  1.797319  13.338054   9.980667  0.011506  0.007269   \n",
      "\n",
      "       7         8            9       ...     4115  4116  4117  4118  4119  \\\n",
      "0  0.067241  0.049107  3406.866211    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "1  0.077000  0.045884  3324.158203    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "2  0.082317  0.044845  3771.984131    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "3  0.069875  0.046916  3301.686035    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "4  0.100647  0.067401  3266.021484    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "\n",
      "   4120  4121  4122      4123      4124  \n",
      "0   NaN   NaN   NaN  0.810875  0.872424  \n",
      "1   NaN   NaN   NaN  0.298856  0.337749  \n",
      "2   NaN   NaN   NaN  0.266423  0.702988  \n",
      "3   NaN   NaN   NaN  0.545639  0.674878  \n",
      "4   NaN   NaN   NaN  0.121416  0.202685  \n",
      "\n",
      "[5 rows x 4125 columns]\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17051 entries, 0 to 17050\n",
      "Columns: 4125 entries, 0 to 4124\n",
      "dtypes: float64(4125)\n",
      "memory usage: 16.4 MB\n",
      "None\n",
      "   0         1         2          3          4         5         6     \\\n",
      "0  29.0  3.821209  1.567568  13.547628   7.242389  0.019883  0.012195   \n",
      "1  25.0  3.052969  1.641484  22.334589  15.734018  0.023027  0.010731   \n",
      "2  82.0  1.601274  1.508805   5.860583   3.301121  0.025948  0.006956   \n",
      "3  25.0  4.819368  2.879584  41.382828  24.448074  0.014387  0.007596   \n",
      "4  29.0  2.768753  1.797319  13.338054   9.980667  0.011506  0.007269   \n",
      "\n",
      "       7         8            9       ...     4115  4116  4117  4118  4119  \\\n",
      "0  0.067241  0.049107  3406.866211    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "1  0.077000  0.045884  3324.158203    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "2  0.082317  0.044845  3771.984131    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "3  0.069875  0.046916  3301.686035    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "4  0.100647  0.067401  3266.021484    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "\n",
      "   4120  4121  4122      4123      4124  \n",
      "0   NaN   NaN   NaN  0.524255  0.866498  \n",
      "1   NaN   NaN   NaN  0.072369  0.534711  \n",
      "2   NaN   NaN   NaN  0.552685  0.918764  \n",
      "3   NaN   NaN   NaN  0.117911  0.223210  \n",
      "4   NaN   NaN   NaN  0.529581  0.968130  \n",
      "\n",
      "[5 rows x 4125 columns]\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39252 entries, 0 to 39251\n",
      "Columns: 4125 entries, 0 to 4124\n",
      "dtypes: float64(4125)\n",
      "memory usage: 38.1 MB\n",
      "None\n",
      "   0         1         2          3          4         5         6     \\\n",
      "0  34.0  7.221330  3.191483  23.518745  11.492748  0.012884  0.010939   \n",
      "1  26.0  6.180094  3.015362  32.932747  18.120752  0.013149  0.010831   \n",
      "2  25.0  2.462173  1.541003  20.039402  18.033579  0.015869  0.011657   \n",
      "3  37.0  6.194136  2.658522  22.864201  13.588374  0.017141  0.012120   \n",
      "4  25.0  4.367200  2.063856  31.797680  14.305157  0.013647  0.013007   \n",
      "\n",
      "       7         8            9       ...     4115  4116  4117  4118  4119  \\\n",
      "0  0.070129  0.042020  3479.684814    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "1  0.075000  0.050982  3362.287354    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "2  0.062625  0.042195  3317.864746    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "3  0.078041  0.072270  3491.640137    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "4  0.107625  0.080645  3327.662109    ...      NaN   NaN   NaN   NaN   NaN   \n",
      "\n",
      "   4120  4121  4122      4123      4124  \n",
      "0   NaN   NaN   NaN  0.340551  0.263356  \n",
      "1   NaN   NaN   NaN  0.969324  0.623752  \n",
      "2   NaN   NaN   NaN  0.148112  0.780920  \n",
      "3   NaN   NaN   NaN  0.746379  0.403130  \n",
      "4   NaN   NaN   NaN  0.572578  0.588162  \n",
      "\n",
      "[5 rows x 4125 columns]\n",
      "\n",
      "\n",
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "df_bbcX      = pd.DataFrame(sdf_bbcX)\n",
    "df_cnnX      = pd.DataFrame(sdf_cnnX)\n",
    "df_cnnibnX   = pd.DataFrame(sdf_cnnibnX)\n",
    "df_ndtvX     = pd.DataFrame(sdf_ndtvX)\n",
    "df_timesnowX = pd.DataFrame(sdf_timesnowX)\n",
    "\n",
    "print(df_bbcX.info())\n",
    "print(df_bbcX.head())\n",
    "print('\\n')\n",
    "print(df_cnnX.info())\n",
    "print(df_cnnX.head())\n",
    "print('\\n')\n",
    "print(df_cnnibnX.info())\n",
    "print(df_cnnibnX.head())\n",
    "print('\\n')\n",
    "print(df_ndtvX.info())\n",
    "print(df_ndtvX.head())\n",
    "print('\\n')\n",
    "print(df_timesnowX.info())\n",
    "print(df_timesnowX.head())\n",
    "print('\\n')\n",
    "\n",
    "print('\\nDONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17720 entries, 0 to 17719\n",
      "Data columns (total 1 columns):\n",
      "0    17720 non-null float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 138.5 KB\n",
      "None\n",
      "     0\n",
      "0  1.0\n",
      "1  1.0\n",
      "2  1.0\n",
      "3  1.0\n",
      "4  1.0\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22545 entries, 0 to 22544\n",
      "Data columns (total 1 columns):\n",
      "0    22545 non-null float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 176.2 KB\n",
      "None\n",
      "     0\n",
      "0  1.0\n",
      "1  1.0\n",
      "2  1.0\n",
      "3  1.0\n",
      "4  1.0\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33117 entries, 0 to 33116\n",
      "Data columns (total 1 columns):\n",
      "0    33117 non-null float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 258.8 KB\n",
      "None\n",
      "     0\n",
      "0  1.0\n",
      "1  1.0\n",
      "2  1.0\n",
      "3  1.0\n",
      "4  1.0\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17051 entries, 0 to 17050\n",
      "Data columns (total 1 columns):\n",
      "0    17051 non-null float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 133.3 KB\n",
      "None\n",
      "     0\n",
      "0  1.0\n",
      "1  1.0\n",
      "2  1.0\n",
      "3  1.0\n",
      "4  1.0\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39252 entries, 0 to 39251\n",
      "Data columns (total 1 columns):\n",
      "0    39252 non-null float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 306.7 KB\n",
      "None\n",
      "     0\n",
      "0  1.0\n",
      "1  1.0\n",
      "2  1.0\n",
      "3  1.0\n",
      "4  1.0\n",
      "\n",
      "\n",
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "df_bbcY      = pd.DataFrame(sdf_bbcY)\n",
    "df_cnnY      = pd.DataFrame(sdf_cnnY)\n",
    "df_cnnibnY   = pd.DataFrame(sdf_cnnibnY)\n",
    "df_ndtvY     = pd.DataFrame(sdf_ndtvY)\n",
    "df_timesnowY = pd.DataFrame(sdf_timesnowY)\n",
    "\n",
    "print(df_bbcY.info())\n",
    "print(df_bbcY.head())\n",
    "print('\\n')\n",
    "print(df_cnnY.info())\n",
    "print(df_cnnY.head())\n",
    "print('\\n')\n",
    "print(df_cnnibnY.info())\n",
    "print(df_cnnibnY.head())\n",
    "print('\\n')\n",
    "print(df_ndtvY.info())\n",
    "print(df_ndtvY.head())\n",
    "print('\\n')\n",
    "print(df_timesnowY.info())\n",
    "print(df_timesnowY.head())\n",
    "print('\\n')\n",
    "\n",
    "print('\\nDONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 148 ms\n",
      "Wall time: 139 ms\n",
      "Wall time: 149 ms\n",
      "Wall time: 131 ms\n",
      "Wall time: 273 ms\n",
      "<class 'pandas.core.sparse.frame.SparseDataFrame'>\n",
      "RangeIndex: 17720 entries, 0 to 17719\n",
      "Columns: 4126 entries, 0 to 0\n",
      "dtypes: float64(4126)\n",
      "memory usage: 14.0 MB\n",
      "None\n",
      "   0         1         2          3         4         5         6     \\\n",
      "0   1.0  1.316440  1.516003   5.605905  5.346760  0.013233  0.010729   \n",
      "1   1.0  0.966079  0.546420   4.046537  3.190973  0.008338  0.011490   \n",
      "2   1.0  2.035407  0.571643   9.551406  5.803685  0.015189  0.014294   \n",
      "3   1.0  3.206008  0.786326  10.092709  2.693058  0.013962  0.011039   \n",
      "4   1.0  3.135861  0.896346  10.348035  2.651010  0.020914  0.012061   \n",
      "\n",
      "       7         8            9     ...   4116  4117  4118  4119  4120  4121  \\\n",
      "0  0.091743  0.050768  3808.067871  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "1  0.075504  0.065841  3466.266113  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "2  0.094209  0.044991  3798.196533  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "3  0.092042  0.043756  3761.712402  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "4  0.108018  0.052617  3784.488037  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "\n",
      "   4122      4123      4124  0     \n",
      "0   NaN  0.422334  0.663918   1.0  \n",
      "1   NaN  0.332664  0.766184   1.0  \n",
      "2   NaN  0.346674  0.225022   1.0  \n",
      "3   NaN  0.993323  0.840083   1.0  \n",
      "4   NaN  0.341520  0.710470   1.0  \n",
      "\n",
      "[5 rows x 4126 columns]\n",
      "\n",
      "\n",
      "<class 'pandas.core.sparse.frame.SparseDataFrame'>\n",
      "RangeIndex: 22545 entries, 0 to 22544\n",
      "Columns: 4126 entries, 0 to 0\n",
      "dtypes: float64(4126)\n",
      "memory usage: 22.3 MB\n",
      "None\n",
      "   0         1         2          3          4         5         6     \\\n",
      "0   1.0  3.821209  1.567568  13.547628   7.242389  0.019883  0.012195   \n",
      "1   1.0  3.052969  1.641484  22.334589  15.734018  0.023027  0.010731   \n",
      "2   1.0  1.601274  1.508805   5.860583   3.301121  0.025948  0.006956   \n",
      "3   1.0  4.819368  2.879584  41.382828  24.448074  0.014387  0.007596   \n",
      "4   1.0  2.768753  1.797319  13.338054   9.980667  0.011506  0.007269   \n",
      "\n",
      "       7         8            9     ...   4116  4117  4118  4119  4120  4121  \\\n",
      "0  0.067241  0.049107  3406.866211  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "1  0.077000  0.045884  3324.158203  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "2  0.082317  0.044845  3771.984131  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "3  0.069875  0.046916  3301.686035  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "4  0.100647  0.067401  3266.021484  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "\n",
      "   4122      4123      4124  0     \n",
      "0   NaN  0.813823  0.397715   1.0  \n",
      "1   NaN  0.171117  0.989377   1.0  \n",
      "2   NaN  0.352850  0.848254   1.0  \n",
      "3   NaN  0.633264  0.553004   1.0  \n",
      "4   NaN  0.529880  0.585360   1.0  \n",
      "\n",
      "[5 rows x 4126 columns]\n",
      "\n",
      "\n",
      "<class 'pandas.core.sparse.frame.SparseDataFrame'>\n",
      "RangeIndex: 33117 entries, 0 to 33116\n",
      "Columns: 4126 entries, 0 to 0\n",
      "dtypes: float64(4126)\n",
      "memory usage: 32.2 MB\n",
      "None\n",
      "   0         1         2          3          4         5         6     \\\n",
      "0   1.0  3.821209  1.567568  13.547628   7.242389  0.019883  0.012195   \n",
      "1   1.0  3.052969  1.641484  22.334589  15.734018  0.023027  0.010731   \n",
      "2   1.0  1.601274  1.508805   5.860583   3.301121  0.025948  0.006956   \n",
      "3   1.0  4.819368  2.879584  41.382828  24.448074  0.014387  0.007596   \n",
      "4   1.0  2.768753  1.797319  13.338054   9.980667  0.011506  0.007269   \n",
      "\n",
      "       7         8            9     ...   4116  4117  4118  4119  4120  4121  \\\n",
      "0  0.067241  0.049107  3406.866211  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "1  0.077000  0.045884  3324.158203  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "2  0.082317  0.044845  3771.984131  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "3  0.069875  0.046916  3301.686035  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "4  0.100647  0.067401  3266.021484  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "\n",
      "   4122      4123      4124  0     \n",
      "0   NaN  0.810875  0.872424   1.0  \n",
      "1   NaN  0.298856  0.337749   1.0  \n",
      "2   NaN  0.266423  0.702988   1.0  \n",
      "3   NaN  0.545639  0.674878   1.0  \n",
      "4   NaN  0.121416  0.202685   1.0  \n",
      "\n",
      "[5 rows x 4126 columns]\n",
      "\n",
      "\n",
      "<class 'pandas.core.sparse.frame.SparseDataFrame'>\n",
      "RangeIndex: 17051 entries, 0 to 17050\n",
      "Columns: 4126 entries, 0 to 0\n",
      "dtypes: float64(4126)\n",
      "memory usage: 16.5 MB\n",
      "None\n",
      "   0         1         2          3          4         5         6     \\\n",
      "0   1.0  3.821209  1.567568  13.547628   7.242389  0.019883  0.012195   \n",
      "1   1.0  3.052969  1.641484  22.334589  15.734018  0.023027  0.010731   \n",
      "2   1.0  1.601274  1.508805   5.860583   3.301121  0.025948  0.006956   \n",
      "3   1.0  4.819368  2.879584  41.382828  24.448074  0.014387  0.007596   \n",
      "4   1.0  2.768753  1.797319  13.338054   9.980667  0.011506  0.007269   \n",
      "\n",
      "       7         8            9     ...   4116  4117  4118  4119  4120  4121  \\\n",
      "0  0.067241  0.049107  3406.866211  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "1  0.077000  0.045884  3324.158203  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "2  0.082317  0.044845  3771.984131  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "3  0.069875  0.046916  3301.686035  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "4  0.100647  0.067401  3266.021484  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "\n",
      "   4122      4123      4124  0     \n",
      "0   NaN  0.524255  0.866498   1.0  \n",
      "1   NaN  0.072369  0.534711   1.0  \n",
      "2   NaN  0.552685  0.918764   1.0  \n",
      "3   NaN  0.117911  0.223210   1.0  \n",
      "4   NaN  0.529581  0.968130   1.0  \n",
      "\n",
      "[5 rows x 4126 columns]\n",
      "\n",
      "\n",
      "<class 'pandas.core.sparse.frame.SparseDataFrame'>\n",
      "RangeIndex: 39252 entries, 0 to 39251\n",
      "Columns: 4126 entries, 0 to 0\n",
      "dtypes: float64(4126)\n",
      "memory usage: 38.4 MB\n",
      "None\n",
      "   0         1         2          3          4         5         6     \\\n",
      "0   1.0  7.221330  3.191483  23.518745  11.492748  0.012884  0.010939   \n",
      "1   1.0  6.180094  3.015362  32.932747  18.120752  0.013149  0.010831   \n",
      "2   1.0  2.462173  1.541003  20.039402  18.033579  0.015869  0.011657   \n",
      "3   1.0  6.194136  2.658522  22.864201  13.588374  0.017141  0.012120   \n",
      "4   1.0  4.367200  2.063856  31.797680  14.305157  0.013647  0.013007   \n",
      "\n",
      "       7         8            9     ...   4116  4117  4118  4119  4120  4121  \\\n",
      "0  0.070129  0.042020  3479.684814  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "1  0.075000  0.050982  3362.287354  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "2  0.062625  0.042195  3317.864746  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "3  0.078041  0.072270  3491.640137  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "4  0.107625  0.080645  3327.662109  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "\n",
      "   4122      4123      4124  0     \n",
      "0   NaN  0.340551  0.263356   1.0  \n",
      "1   NaN  0.969324  0.623752   1.0  \n",
      "2   NaN  0.148112  0.780920   1.0  \n",
      "3   NaN  0.746379  0.403130   1.0  \n",
      "4   NaN  0.572578  0.588162   1.0  \n",
      "\n",
      "[5 rows x 4126 columns]\n",
      "\n",
      "\n",
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "%time df_bbc      = pd.concat([df_bbcX, df_bbcY], axis=1)\n",
    "%time df_cnn      = pd.concat([df_cnnX, df_cnnY], axis=1)\n",
    "%time df_cnnibn   = pd.concat([df_cnnibnX, df_cnnibnY], axis=1)\n",
    "%time df_ndtv     = pd.concat([df_ndtvX, df_ndtvY], axis=1)\n",
    "%time df_timesnow = pd.concat([df_timesnowX, df_timesnowY], axis=1)\n",
    "\n",
    "print(df_bbc.info())\n",
    "print(df_bbc.head())\n",
    "print('\\n')\n",
    "print(df_cnn.info())\n",
    "print(df_cnn.head())\n",
    "print('\\n')\n",
    "print(df_cnnibn.info())\n",
    "print(df_cnnibn.head())\n",
    "print('\\n')\n",
    "print(df_ndtv.info())\n",
    "print(df_ndtv.head())\n",
    "print('\\n')\n",
    "print(df_timesnow.info())\n",
    "print(df_timesnow.head())\n",
    "print('\\n')\n",
    "\n",
    "print('\\nDONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Merge the Pandas Sparse Dataframes\n",
    "\n",
    "This step prepends the Y-Axis to the X-Axis by concatenating the two Pandas Sparse Dataframes. This aligns the dependent variable (Dimension Index) as the first column in the dataframe and the remaining columns as the independent variables.\n",
    "\n",
    "Note: This step takes about 5 seconds (~1 second for each concatenation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 125 ms\n",
      "Wall time: 309 ms\n",
      "Wall time: 133 ms\n",
      "Wall time: 127 ms\n",
      "Wall time: 143 ms\n",
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "%time sdf_concat_bbc      = pd.concat([sdf_bbcX, sdf_bbcY], axis=1)\n",
    "%time sdf_concat_cnn      = pd.concat([sdf_cnnX, sdf_cnnY], axis=1)\n",
    "%time sdf_concat_cnnibn   = pd.concat([sdf_cnnibnX, sdf_cnnibnY], axis=1)\n",
    "%time sdf_concat_ndtv     = pd.concat([sdf_ndtvX, sdf_ndtvY], axis=1)\n",
    "%time sdf_concat_timesnow = pd.concat([sdf_timesnowX, sdf_timesnowY], axis=1)\n",
    "\n",
    "print('\\nDONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.sparse.frame.SparseDataFrame'>\n",
      "RangeIndex: 17720 entries, 0 to 17719\n",
      "Columns: 4126 entries, 0 to 0\n",
      "dtypes: float64(4126)\n",
      "memory usage: 14.0 MB\n",
      "<class 'pandas.core.sparse.frame.SparseDataFrame'>\n",
      "RangeIndex: 22545 entries, 0 to 22544\n",
      "Columns: 4126 entries, 0 to 0\n",
      "dtypes: float64(4126)\n",
      "memory usage: 22.3 MB\n",
      "<class 'pandas.core.sparse.frame.SparseDataFrame'>\n",
      "RangeIndex: 33117 entries, 0 to 33116\n",
      "Columns: 4126 entries, 0 to 0\n",
      "dtypes: float64(4126)\n",
      "memory usage: 32.2 MB\n",
      "<class 'pandas.core.sparse.frame.SparseDataFrame'>\n",
      "RangeIndex: 17051 entries, 0 to 17050\n",
      "Columns: 4126 entries, 0 to 0\n",
      "dtypes: float64(4126)\n",
      "memory usage: 16.5 MB\n",
      "<class 'pandas.core.sparse.frame.SparseDataFrame'>\n",
      "RangeIndex: 39252 entries, 0 to 39251\n",
      "Columns: 4126 entries, 0 to 0\n",
      "dtypes: float64(4126)\n",
      "memory usage: 38.4 MB\n",
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "sdf_concat_bbc.info()\n",
    "sdf_concat_cnn.info()\n",
    "sdf_concat_cnnibn.info()\n",
    "sdf_concat_ndtv.info()\n",
    "sdf_concat_timesnow.info()\n",
    "\n",
    "print('\\nDONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Concatenate into a Single Pandas Sparse DataFrame\n",
    "\n",
    "Now that all five datasets have been reduced into a fixed matrix, concatenate these fixed matrix arrays into a single Pandas DataFrame. Thus, consolidating five operations into one for the rest of this notebook.\n",
    "\n",
    "Note: This code executes in about 10 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17720 entries, 0 to 17719\n",
      "Columns: 4126 entries, 0 to 0\n",
      "dtypes: float64(4126)\n",
      "memory usage: 14.0 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22545 entries, 0 to 22544\n",
      "Columns: 4126 entries, 0 to 0\n",
      "dtypes: float64(4126)\n",
      "memory usage: 22.3 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33117 entries, 0 to 33116\n",
      "Columns: 4126 entries, 0 to 0\n",
      "dtypes: float64(4126)\n",
      "memory usage: 32.2 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17051 entries, 0 to 17050\n",
      "Columns: 4126 entries, 0 to 0\n",
      "dtypes: float64(4126)\n",
      "memory usage: 16.5 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39252 entries, 0 to 39251\n",
      "Columns: 4126 entries, 0 to 0\n",
      "dtypes: float64(4126)\n",
      "memory usage: 38.4 MB\n",
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# Convert to fixed matrix\n",
    "\n",
    "df_concat_bbc      = pd.DataFrame(sdf_concat_bbc)\n",
    "df_concat_cnn      = pd.DataFrame(sdf_concat_cnn)\n",
    "df_concat_cnnibn   = pd.DataFrame(sdf_concat_cnnibn)\n",
    "df_concat_ndtv     = pd.DataFrame(sdf_concat_ndtv)\n",
    "df_concat_timesnow = pd.DataFrame(sdf_concat_timesnow)\n",
    "\n",
    "df_concat_bbc.info()\n",
    "df_concat_cnn.info()\n",
    "df_concat_cnnibn.info()\n",
    "df_concat_ndtv.info()\n",
    "df_concat_timesnow.info()\n",
    "\n",
    "print('\\nDONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4116</th>\n",
       "      <th>4117</th>\n",
       "      <th>4118</th>\n",
       "      <th>4119</th>\n",
       "      <th>4120</th>\n",
       "      <th>4121</th>\n",
       "      <th>4122</th>\n",
       "      <th>4123</th>\n",
       "      <th>4124</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.0</td>\n",
       "      <td>1.316440</td>\n",
       "      <td>1.516003</td>\n",
       "      <td>5.605905</td>\n",
       "      <td>5.346760</td>\n",
       "      <td>0.013233</td>\n",
       "      <td>0.010729</td>\n",
       "      <td>0.091743</td>\n",
       "      <td>0.050768</td>\n",
       "      <td>3808.067871</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.422334</td>\n",
       "      <td>0.663918</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124.0</td>\n",
       "      <td>0.966079</td>\n",
       "      <td>0.546420</td>\n",
       "      <td>4.046537</td>\n",
       "      <td>3.190973</td>\n",
       "      <td>0.008338</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.075504</td>\n",
       "      <td>0.065841</td>\n",
       "      <td>3466.266113</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.332664</td>\n",
       "      <td>0.766184</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109.0</td>\n",
       "      <td>2.035407</td>\n",
       "      <td>0.571643</td>\n",
       "      <td>9.551406</td>\n",
       "      <td>5.803685</td>\n",
       "      <td>0.015189</td>\n",
       "      <td>0.014294</td>\n",
       "      <td>0.094209</td>\n",
       "      <td>0.044991</td>\n",
       "      <td>3798.196533</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.346674</td>\n",
       "      <td>0.225022</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86.0</td>\n",
       "      <td>3.206008</td>\n",
       "      <td>0.786326</td>\n",
       "      <td>10.092709</td>\n",
       "      <td>2.693058</td>\n",
       "      <td>0.013962</td>\n",
       "      <td>0.011039</td>\n",
       "      <td>0.092042</td>\n",
       "      <td>0.043756</td>\n",
       "      <td>3761.712402</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993323</td>\n",
       "      <td>0.840083</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76.0</td>\n",
       "      <td>3.135861</td>\n",
       "      <td>0.896346</td>\n",
       "      <td>10.348035</td>\n",
       "      <td>2.651010</td>\n",
       "      <td>0.020914</td>\n",
       "      <td>0.012061</td>\n",
       "      <td>0.108018</td>\n",
       "      <td>0.052617</td>\n",
       "      <td>3784.488037</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.341520</td>\n",
       "      <td>0.710470</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2          3         4         5         6     \\\n",
       "0  123.0  1.316440  1.516003   5.605905  5.346760  0.013233  0.010729   \n",
       "1  124.0  0.966079  0.546420   4.046537  3.190973  0.008338  0.011490   \n",
       "2  109.0  2.035407  0.571643   9.551406  5.803685  0.015189  0.014294   \n",
       "3   86.0  3.206008  0.786326  10.092709  2.693058  0.013962  0.011039   \n",
       "4   76.0  3.135861  0.896346  10.348035  2.651010  0.020914  0.012061   \n",
       "\n",
       "       7         8            9     ...   4116  4117  4118  4119  4120  4121  \\\n",
       "0  0.091743  0.050768  3808.067871  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1  0.075504  0.065841  3466.266113  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "2  0.094209  0.044991  3798.196533  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "3  0.092042  0.043756  3761.712402  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "4  0.108018  0.052617  3784.488037  ...    NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "   4122      4123      4124  0     \n",
       "0   NaN  0.422334  0.663918   1.0  \n",
       "1   NaN  0.332664  0.766184   1.0  \n",
       "2   NaN  0.346674  0.225022   1.0  \n",
       "3   NaN  0.993323  0.840083   1.0  \n",
       "4   NaN  0.341520  0.710470   1.0  \n",
       "\n",
       "[5 rows x 4126 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat_bbc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.86 s\n",
      "\n",
      "\n",
      "<class 'pandas.core.sparse.frame.SparseDataFrame'>\n",
      "Int64Index: 40265 entries, 0 to 22544\n",
      "Columns: 4126 entries, 0 to 0\n",
      "dtypes: float64(4126)\n",
      "memory usage: 36.5 MB\n",
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "#frames = [df_concat_bbc, df_concat_cnn, df_concat_cnnibn, df_concat_ndtv, df_concat_timesnow]\n",
    "frames = [df_concat_bbc, df_concat_cnn]\n",
    "\n",
    "%time df_concat = pd.concat(frames)\n",
    "\n",
    "print('\\n')\n",
    "df_concat.info()\n",
    "\n",
    "print('\\nDONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40265"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_concat.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Reduce Sparseness of the X-axis (First Pass)\n",
    "\n",
    "The reason this is a sparse matrix is primarily due to the following four features:\n",
    "\n",
    "> Motion Distribution (columns 18 - 58)\n",
    "\n",
    "> Frame Difference Distribution (columns 59 - 91)\n",
    "\n",
    "> Text area distribution (columns 92 - 122)\n",
    "\n",
    "> Bag of Audio Words (columns 123 - 4123)\n",
    "\n",
    "\n",
    "The assumption is that these columns could even be empty. Consequently, this step will all inspect all columns that are completely empty (i.e., all column values are NaN (Not a Number) and then remove those columns if they are empty. The assumption is that all columns before Motion Distribution (columns 18 - 58) have date (i.e., they are not sparse). Hence, if any columns before column 18 are empty, this step will print that column number for reference. (Others are simple deleted.)\n",
    "\n",
    "Note: This step takes about 20 minutes to execute (about 4 minutes per sparsed matrix object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sdf_concat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-30ef6aa24a46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msdf_concat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_concat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_concat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sdf_concat' is not defined"
     ]
    }
   ],
   "source": [
    "df_concat = pd.DataFrame(sdf_concat)\n",
    "\n",
    "for i in df_concat:\n",
    "    print(df_concat[i])\n",
    "    \n",
    "print('\\nDONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting all columns that have all values that are 100% NaN (Not a Number) ...\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BlockManager' object has no attribute 'T'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-38bb3828d5e5>\u001b[0m in \u001b[0;36mdelete_nan_columns\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mtotal_nan_rows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtotal_nan_rows\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\sparse\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    430\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1841\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1843\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1845\u001b[0m             \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_as_cached\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_box_item_values\u001b[1;34m(self, key, values)\u001b[0m\n\u001b[0;32m   2494\u001b[0m         \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2495\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2496\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2497\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2498\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_col_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BlockManager' object has no attribute 'T'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Delete any column that has 100% of its rows as Not a Number (NaN)\n",
    "################################################################################\n",
    "\n",
    "def delete_nan_columns(df):\n",
    "    total_rows_deleted = 0\n",
    "    \n",
    "    for i in df:\n",
    "        total_nan_rows = df[i].isnull().sum()\n",
    "        if (total_nan_rows == len(df.index)):\n",
    "            del df[i]\n",
    "            total_rows_deleted = total_rows_deleted + 1\n",
    "\n",
    "    return total_rows_deleted\n",
    "\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "print('\\nDeleting all columns that have all values that are 100% NaN (Not a Number) ...\\n')\n",
    "\n",
    "%time total_nan_cols = delete_nan_columns(df_concat)\n",
    "\n",
    "#%time total_nan_cnn_cols      = delete_nan_columns(sdf_cnnX)\n",
    "#%time total_nan_cnnibn_cols   = delete_nan_columns(sdf_cnnibnX)\n",
    "#%time total_nan_ndtv_cols     = delete_nan_columns(sdf_ndtvX)\n",
    "#%time total_nan_timesnow_cols = delete_nan_columns(sdf_timesnowX)\n",
    "\n",
    "#print('\\nNaN columns have been deleted (out of 4,125)\\n')\n",
    "\n",
    "#print('bbc:      ', total_nan_cols)\n",
    "#print('cnn:      ', total_nan_cnn_cols)\n",
    "#print('cnnibn:   ', total_nan_cnnibn_cols)\n",
    "#print('ndtv:     ', total_nan_ndtv_cols)\n",
    "#print('timesnow: ', total_nan_timesnow_cols)\n",
    "\n",
    "print('\\nDONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Inspect the Dependent Variable (Dimension Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sm_bbc - count of +1 and -1 values, and total:  8416 9304 17720\n",
      "sm_cnn - count of +1 and -1 values, and total:  14411 8134 22545\n",
      "sm_cnnibn - count of +1 and -1 values, and total:  21693 11424 33117\n",
      "sm_ndtv - count of +1 and -1 values, and total:  12564 4487 17051\n",
      "sm_ndtv - count of +1 and -1 values, and total:  25147 14105 39252\n",
      "Grand total:  129685\n",
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# This code creates a Pandas Series from the Y axis, and then prepends that to the beginning of the Pandas Sparse Dataframes\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "tot_y_pos_1_bbc = np.count_nonzero(sm_bbc[1] == 1)\n",
    "tot_y_neg_1_bbc = np.count_nonzero(sm_bbc[1] == -1)\n",
    "tot_bbc = tot_y_pos_1_bbc + tot_y_neg_1_bbc\n",
    "\n",
    "print('sm_bbc - count of +1 and -1 values, and total: ', tot_y_pos_1_bbc, tot_y_neg_1_bbc, tot_bbc)\n",
    "\n",
    "tot_y_pos_1_cnn = np.count_nonzero(sm_cnn[1] == 1)\n",
    "tot_y_neg_1_cnn = np.count_nonzero(sm_cnn[1] == -1)\n",
    "tot_cnn = tot_y_pos_1_cnn + tot_y_neg_1_cnn\n",
    "\n",
    "print('sm_cnn - count of +1 and -1 values, and total: ', tot_y_pos_1_cnn, tot_y_neg_1_cnn, tot_cnn)\n",
    "\n",
    "tot_y_pos_1_cnnibn = np.count_nonzero(sm_cnnibn[1] == 1)\n",
    "tot_y_neg_1_cnnibn = np.count_nonzero(sm_cnnibn[1] == -1)\n",
    "tot_cnnibn = tot_y_pos_1_cnnibn + tot_y_neg_1_cnnibn\n",
    "\n",
    "print('sm_cnnibn - count of +1 and -1 values, and total: ', tot_y_pos_1_cnnibn, tot_y_neg_1_cnnibn, tot_cnnibn)\n",
    "\n",
    "tot_y_pos_1_ndtv = np.count_nonzero(sm_ndtv[1] == 1)\n",
    "tot_y_neg_1_ndtv = np.count_nonzero(sm_ndtv[1] == -1)\n",
    "tot_ndtv = tot_y_pos_1_ndtv + tot_y_neg_1_ndtv\n",
    "\n",
    "print('sm_ndtv - count of +1 and -1 values, and total: ', tot_y_pos_1_ndtv, tot_y_neg_1_ndtv, tot_ndtv)\n",
    "\n",
    "tot_y_pos_1_timesnow = np.count_nonzero(sm_timesnow[1] == 1)\n",
    "tot_y_neg_1_timesnow = np.count_nonzero(sm_timesnow[1] == -1)\n",
    "tot_timesnow = tot_y_pos_1_timesnow + tot_y_neg_1_timesnow\n",
    "\n",
    "print('sm_ndtv - count of +1 and -1 values, and total: ', tot_y_pos_1_timesnow, tot_y_neg_1_timesnow, tot_timesnow)\n",
    "\n",
    "grand_total = tot_bbc + tot_cnn + tot_cnnibn + tot_ndtv + tot_timesnow\n",
    "\n",
    "print('Grand total: ', grand_total)\n",
    "\n",
    "print('\\nDONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Convert to Normal Dataframes\n",
    "\n",
    "Now that thousands of useless columns have been deleted, this step will convert the Sparse DataFrame to a normal DataFrame. This will convert the sparse matrix to a fixed matrix and greatly improve performance in further data analysis.\n",
    "\n",
    "Note: This cell runs is just a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbc:       17720\n",
      "cnn:       22545\n",
      "cnnibn:    33117\n",
      "ndtv:      17051\n",
      "timesnow:  39252\n",
      "\n",
      "Total rows:  129685\n",
      "\n",
      "\n",
      "Wall time: 0 ns\n",
      "Wall time: 0 ns\n",
      "Wall time: 0 ns\n",
      "Wall time: 0 ns\n",
      "Wall time: 0 ns\n",
      "\n",
      "bbc:       17720\n",
      "cnn:       22545\n",
      "cnnibn:    33117\n",
      "ndtv:      17051\n",
      "timesnow:  39252\n",
      "\n",
      "Total rows:  129685\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17720 entries, 0 to 17719\n",
      "Columns: 4126 entries, 0 to 0\n",
      "dtypes: float64(4126)\n",
      "memory usage: 14.0 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22545 entries, 0 to 22544\n",
      "Columns: 4126 entries, 0 to 0\n",
      "dtypes: float64(4126)\n",
      "memory usage: 22.3 MB\n",
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: the total number of row should not have changed when deleting columns\n",
    "\n",
    "print('bbc:      ', len(sdf_concat_bbc.index))\n",
    "print('cnn:      ', len(sdf_concat_cnn.index))\n",
    "print('cnnibn:   ', len(sdf_concat_cnnibn.index))\n",
    "print('ndtv:     ', len(sdf_concat_ndtv.index))\n",
    "print('timesnow: ', len(sdf_concat_timesnow.index))\n",
    "\n",
    "print('\\nTotal rows: ', len(sdf_concat_bbc.index) + len(sdf_concat_cnn.index) + len(sdf_concat_cnnibn.index) + len(sdf_concat_ndtv.index) + len(sdf_concat_timesnow.index))\n",
    "\n",
    "# Convert sparse matrix arrays to fixed arrays (now that most of the columns have been deleted)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "%time df_bbc      = pd.DataFrame(sdf_concat_bbc)\n",
    "%time df_cnn      = pd.DataFrame(sdf_concat_cnn)\n",
    "%time df_cnnibn   = pd.DataFrame(sdf_concat_cnnibn)\n",
    "%time df_ndtv     = pd.DataFrame(sdf_concat_ndtv)\n",
    "%time df_timesnow = pd.DataFrame(sdf_concat_timesnow)\n",
    "\n",
    "print('\\nbbc:      ', len(df_bbc.index))\n",
    "print('cnn:      ', len(df_cnn.index))\n",
    "print('cnnibn:   ', len(df_cnnibn.index))\n",
    "print('ndtv:     ', len(df_ndtv.index))\n",
    "print('timesnow: ', len(df_timesnow.index))\n",
    "\n",
    "print('\\nTotal rows: ', len(df_bbc.index) + len(df_cnn.index) + len(df_cnnibn.index) + len(df_ndtv.index) + len(df_timesnow.index))\n",
    "\n",
    "#print(df_bbc.head())\n",
    "#print(df_cnn.head())\n",
    "#print(df_cnnibn.head())\n",
    "#print(df_ndtv.head())\n",
    "#print(df_timesnow.head())\n",
    "\n",
    "df_bbc.info()\n",
    "df_cnn.info()\n",
    "\n",
    "print('\\nDONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Eliminate Unused Columns (Second Pass)\n",
    "\n",
    "Now that the datasets have been consolidated, columns with more that X% NaN elements will be deleted to further reduce sparsity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BlockManager' object has no attribute 'T'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-0b09fd3f9c26>\u001b[0m in \u001b[0;36mpercent_nan_columns\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mtotal_nan_rows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mpercent_nan_rows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_nan_rows\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\sparse\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    430\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1841\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1843\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1845\u001b[0m             \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_as_cached\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_box_item_values\u001b[1;34m(self, key, values)\u001b[0m\n\u001b[0;32m   2494\u001b[0m         \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2495\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2496\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2497\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2498\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_col_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BlockManager' object has no attribute 'T'"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'my_df_bbc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-0b09fd3f9c26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time percent_nan_columns(df_concat)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmy_df_bbc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m86\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_df_bbc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'my_df_bbc' is not defined"
     ]
    }
   ],
   "source": [
    "# NOT DONE YET -- WIP\n",
    "\n",
    "def percent_nan_columns(df):\n",
    "    percent_nan_threshold = 0.9\n",
    "    total_nan_cols = 0\n",
    "\n",
    "    for i in df:\n",
    "        total_nan_rows = df[i].isnull().sum()\n",
    "\n",
    "        percent_nan_rows = total_nan_rows / len(df.index)\n",
    "\n",
    "        #if (percent_nan_rows > percent_nan_threshold):\n",
    "            #print('Column: ', i, total_nan_rows, percent_nan_rows)\n",
    "\n",
    "    return total_nan_cols\n",
    "\n",
    "%time percent_nan_columns(df_concat)\n",
    "\n",
    "for i in my_df_bbc:\n",
    "    if i == 86:\n",
    "        print(my_df_bbc[i])\n",
    "        \n",
    "print('\\nDONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hexagon Bin Plot\n",
    "A hexagon bin plot can be created using the DataFrame.plot() function and kind = 'hexbin'. \n",
    "\n",
    "This kind of plot is really useful if your scatter plot is too dense to interpret. It helps in binning the spatial area of the chart and the intensity of the color that a hexagon can be interpreted as points being more concentrated in this area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST\n",
      "Aw, snap! We don't have an account for ''. Want to try again? You can authenticate with your email address or username. Sign in is not case sensitive.\n",
      "\n",
      "Don't have an account? plot.ly\n",
      "\n",
      "Questions? support@plot.ly\n"
     ]
    },
    {
     "ename": "PlotlyError",
     "evalue": "Because you didn't supply a 'file_id' in the call, we're assuming you're trying to snag a figure from a url. You supplied the url, '', we expected it to start with 'https://plot.ly'.\nRun help on this function for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPlotlyError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-67735ddf5c75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHistogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'basic histogram'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#print('\\nData Frame Shape:')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\plotly\\plotly\\plotly.py\u001b[0m in \u001b[0;36miplot\u001b[1;34m(figure_or_data, **plot_options)\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0membed_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'height'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membed_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'height'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'px'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0membed_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\plotly\\tools.py\u001b[0m in \u001b[0;36membed\u001b[1;34m(file_owner_or_url, file_id, width, height)\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_owner_or_url\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mPlotlyDisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         if (get_config_defaults()['plotly_domain']\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\plotly\\tools.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, url, width, height)\u001b[0m\n\u001b[0;32m   1363\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_embed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPlotlyDisplay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\plotly\\tools.py\u001b[0m in \u001b[0;36mget_embed\u001b[1;34m(file_owner_or_url, file_id, width, height)\u001b[0m\n\u001b[0;32m    293\u001b[0m                 \u001b[1;34m\"'{1}'.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                 \u001b[1;34m\"\\nRun help on this function for more information.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \"\".format(url, plotly_rest_url))\n\u001b[0m\u001b[0;32m    296\u001b[0m         \u001b[0murlsplit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[0mfile_owner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlsplit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'~'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPlotlyError\u001b[0m: Because you didn't supply a 'file_id' in the call, we're assuming you're trying to snag a figure from a url. You supplied the url, '', we expected it to start with 'https://plot.ly'.\nRun help on this function for more information."
     ]
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print('\\nTEST')\n",
    "\n",
    "x = np.random.randn(500)\n",
    "data = [go.Histogram(x=x)]\n",
    "\n",
    "py.iplot(data, filename='basic histogram')\n",
    "\n",
    "#print('\\nData Frame Shape:')\n",
    "#print(df_bbc.shape)\n",
    "\n",
    "#print('\\nCreating Table...')\n",
    "#table = ff.create_table(df_bbc)\n",
    "\n",
    "#print('\\nPlotting...')\n",
    "#py.iplot(table, filename='jupyter/table1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
